{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_boston, load_diabetes\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "print(type(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if []:\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "diabetes = load_diabetes(as_frame=True).frame\n",
    "print(type(diabetes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019908 -0.017646   151.0  \n",
       "1   -0.039493 -0.068330 -0.092204    75.0  \n",
       "2   -0.002592  0.002864 -0.025930   141.0  \n",
       "3    0.034309  0.022692 -0.009362   206.0  \n",
       "4   -0.002592 -0.031991 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018118  0.044485   104.0  \n",
       "439 -0.011080 -0.046879  0.015491   132.0  \n",
       "440  0.026560  0.044528 -0.025930   220.0  \n",
       "441 -0.039493 -0.004220  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'target'\n",
    "diabetes[target].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes[target].dtype == 'float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes[target].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['target'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[target].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-6e97dff6edb0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iris[target][-1] = 'test'\n"
     ]
    }
   ],
   "source": [
    "iris[target][-1] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of  0         0\n",
       " 1         0\n",
       " 2         0\n",
       " 3         0\n",
       " 4         0\n",
       "        ... \n",
       " 146       2\n",
       " 147       2\n",
       " 148       2\n",
       " 149       2\n",
       "-1      test\n",
       "Name: target, Length: 151, dtype: object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[target].tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[target].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( iris['data'] == iris['data'] ).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, r2_score, make_scorer\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'Precision': make_scorer(precision_score, average='weighted')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "dt = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = RepeatedKFold(n_splits=10, n_repeats=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.20012641, 0.17563581, 0.12492871, 0.12395453, 0.1219182 ,\n",
      "       0.12407136, 0.1518786 , 0.1228323 , 0.12191582, 0.15226698,\n",
      "       0.16295481, 0.12156129, 0.12238336, 0.11833835, 0.11661506,\n",
      "       0.15130734, 0.11554575, 0.11307979, 0.11227608, 0.11825919]), 'score_time': array([0.00941086, 0.00880504, 0.00809193, 0.00864935, 0.00771356,\n",
      "       0.0077424 , 0.00866079, 0.00771499, 0.00858951, 0.00998259,\n",
      "       0.00852966, 0.00799203, 0.00840139, 0.00756955, 0.00786209,\n",
      "       0.00827837, 0.00782847, 0.00759792, 0.00759268, 0.00776982]), 'test_score': array([1.        , 1.        , 0.93333333, 0.8       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.86666667, 0.93333333,\n",
      "       0.86666667, 1.        , 0.86666667, 1.        , 0.93333333,\n",
      "       1.        , 1.        , 1.        , 0.86666667, 1.        ])}\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate( rf, X, y, scoring='accuracy', cv=rkf )\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate( rf, X, y, scoring=scorer, cv=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc avg: 0.96\n",
      "Acc std: 0.0442\n",
      "Rec avg: 0.96\n",
      "Rec std: 0.0442\n",
      "Prec avg: 0.9644\n",
      "Prec std: 0.0418\n"
     ]
    }
   ],
   "source": [
    "acc_scores = scores['test_Accuracy']\n",
    "acc_avg = round( np.mean(acc_scores), 4 )\n",
    "acc_std = round( np.std(acc_scores), 4 )\n",
    "print('Acc avg: {}'.format(acc_avg))\n",
    "print('Acc std: {}'.format(acc_std))\n",
    "\n",
    "rec_scores = scores['test_Recall']\n",
    "rec_avg = round( np.mean(rec_scores), 4 )\n",
    "rec_std = round( np.std(rec_scores), 4 )\n",
    "print('Rec avg: {}'.format(rec_avg))\n",
    "print('Rec std: {}'.format(rec_std))\n",
    "\n",
    "prec_scores = scores['test_Precision']\n",
    "prec_avg = round( np.mean(prec_scores), 4 )\n",
    "prec_std = round( np.std(prec_scores), 4 )\n",
    "print('Prec avg: {}'.format(prec_avg))\n",
    "print('Prec std: {}'.format(prec_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate( dt, X, y, scoring=scorer, cv=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc avg: 0.96\n",
      "Acc std: 0.0442\n",
      "Rec avg: 0.96\n",
      "Rec std: 0.0442\n",
      "Prec avg: 0.9644\n",
      "Prec std: 0.0418\n"
     ]
    }
   ],
   "source": [
    "acc_scores = scores['test_Accuracy']\n",
    "acc_avg = round( np.mean(acc_scores), 4 )\n",
    "acc_std = round( np.std(acc_scores), 4 )\n",
    "print('Acc avg: {}'.format(acc_avg))\n",
    "print('Acc std: {}'.format(acc_std))\n",
    "\n",
    "rec_scores = scores['test_Recall']\n",
    "rec_avg = round( np.mean(rec_scores), 4 )\n",
    "rec_std = round( np.std(rec_scores), 4 )\n",
    "print('Rec avg: {}'.format(rec_avg))\n",
    "print('Rec std: {}'.format(rec_std))\n",
    "\n",
    "prec_scores = scores['test_Precision']\n",
    "prec_avg = round( np.mean(prec_scores), 4 )\n",
    "prec_std = round( np.std(prec_scores), 4 )\n",
    "print('Prec avg: {}'.format(prec_avg))\n",
    "print('Prec std: {}'.format(prec_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X, y)\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y\n",
    "y_pred = rf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred, multi_class=\"ovr\", average=\"weighted\")\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y\n",
    "y_pred = dt.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true, y_pred, multi_class=\"ovr\", average=\"weighted\")\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_auc(y_true, y_pred):\n",
    "    return roc_auc_score(y_true, y_pred, multi_class=\"ovr\", average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = { \n",
    "    'auc': make_scorer(\n",
    "        custom_auc, \n",
    "        needs_proba=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.95 1.   0.95 0.95 0.9  0.95 1.   1.   1.  ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate( dt, X, y, scoring=custom_scorer, cv=10 )\n",
    "print(scores['test_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "dt = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "def custom_auc_reg(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=2)\n",
    "    print(Counter(y_true))\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "custom_scorer_reg = { \n",
    "    'auc': make_scorer(\n",
    "        custom_auc_reg\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = {\n",
    "    'R2': make_scorer(r2_score),\n",
    "    'AUC': make_scorer(\n",
    "        custom_auc_reg \n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({97.0: 2, 68.0: 2, 151.0: 1, 75.0: 1, 141.0: 1, 206.0: 1, 135.0: 1, 138.0: 1, 63.0: 1, 110.0: 1, 310.0: 1, 101.0: 1, 69.0: 1, 179.0: 1, 185.0: 1, 118.0: 1, 171.0: 1, 166.0: 1, 144.0: 1, 168.0: 1, 49.0: 1, 245.0: 1, 184.0: 1, 202.0: 1, 137.0: 1, 85.0: 1, 131.0: 1, 283.0: 1, 129.0: 1, 59.0: 1, 341.0: 1, 87.0: 1, 65.0: 1, 102.0: 1, 265.0: 1, 276.0: 1, 252.0: 1, 90.0: 1, 100.0: 1, 55.0: 1, 61.0: 1, 92.0: 1, 259.0: 1})\n",
      "Counter({52.0: 3, 170.0: 3, 142.0: 2, 128.0: 2, 111.0: 2, 42.0: 2, 53.0: 1, 190.0: 1, 75.0: 1, 155.0: 1, 225.0: 1, 59.0: 1, 104.0: 1, 182.0: 1, 37.0: 1, 61.0: 1, 144.0: 1, 71.0: 1, 163.0: 1, 150.0: 1, 97.0: 1, 160.0: 1, 178.0: 1, 48.0: 1, 270.0: 1, 202.0: 1, 85.0: 1, 200.0: 1, 252.0: 1, 113.0: 1, 143.0: 1, 51.0: 1, 210.0: 1, 65.0: 1, 141.0: 1, 55.0: 1, 134.0: 1})\n",
      "Counter({83.0: 2, 200.0: 2, 98.0: 1, 164.0: 1, 48.0: 1, 96.0: 1, 90.0: 1, 162.0: 1, 150.0: 1, 279.0: 1, 92.0: 1, 128.0: 1, 102.0: 1, 302.0: 1, 198.0: 1, 95.0: 1, 53.0: 1, 134.0: 1, 144.0: 1, 232.0: 1, 81.0: 1, 104.0: 1, 59.0: 1, 246.0: 1, 297.0: 1, 258.0: 1, 229.0: 1, 275.0: 1, 281.0: 1, 179.0: 1, 173.0: 1, 180.0: 1, 84.0: 1, 121.0: 1, 161.0: 1, 99.0: 1, 109.0: 1, 115.0: 1, 268.0: 1, 274.0: 1, 158.0: 1, 107.0: 1})\n",
      "Counter({96.0: 2, 103.0: 1, 272.0: 1, 85.0: 1, 280.0: 1, 336.0: 1, 281.0: 1, 118.0: 1, 317.0: 1, 235.0: 1, 60.0: 1, 174.0: 1, 259.0: 1, 178.0: 1, 128.0: 1, 126.0: 1, 288.0: 1, 88.0: 1, 292.0: 1, 71.0: 1, 197.0: 1, 186.0: 1, 25.0: 1, 84.0: 1, 195.0: 1, 53.0: 1, 217.0: 1, 172.0: 1, 131.0: 1, 214.0: 1, 59.0: 1, 70.0: 1, 220.0: 1, 268.0: 1, 152.0: 1, 47.0: 1, 74.0: 1, 295.0: 1, 101.0: 1, 151.0: 1, 127.0: 1, 237.0: 1, 225.0: 1})\n",
      "Counter({185.0: 2, 196.0: 2, 81.0: 1, 151.0: 1, 107.0: 1, 64.0: 1, 138.0: 1, 265.0: 1, 101.0: 1, 137.0: 1, 143.0: 1, 141.0: 1, 79.0: 1, 292.0: 1, 178.0: 1, 91.0: 1, 116.0: 1, 86.0: 1, 122.0: 1, 72.0: 1, 129.0: 1, 142.0: 1, 90.0: 1, 158.0: 1, 39.0: 1, 222.0: 1, 277.0: 1, 99.0: 1, 202.0: 1, 155.0: 1, 77.0: 1, 191.0: 1, 70.0: 1, 73.0: 1, 49.0: 1, 65.0: 1, 263.0: 1, 248.0: 1, 296.0: 1, 214.0: 1, 78.0: 1, 93.0: 1})\n",
      "Counter({150.0: 2, 77.0: 2, 252.0: 1, 208.0: 1, 108.0: 1, 160.0: 1, 53.0: 1, 220.0: 1, 154.0: 1, 259.0: 1, 90.0: 1, 246.0: 1, 124.0: 1, 67.0: 1, 72.0: 1, 257.0: 1, 262.0: 1, 275.0: 1, 177.0: 1, 71.0: 1, 47.0: 1, 187.0: 1, 125.0: 1, 78.0: 1, 51.0: 1, 258.0: 1, 215.0: 1, 303.0: 1, 243.0: 1, 91.0: 1, 310.0: 1, 153.0: 1, 346.0: 1, 63.0: 1, 89.0: 1, 50.0: 1, 39.0: 1, 103.0: 1, 308.0: 1, 116.0: 1, 145.0: 1, 74.0: 1})\n",
      "Counter({94.0: 2, 200.0: 2, 45.0: 1, 115.0: 1, 264.0: 1, 87.0: 1, 202.0: 1, 127.0: 1, 182.0: 1, 241.0: 1, 66.0: 1, 283.0: 1, 64.0: 1, 102.0: 1, 265.0: 1, 230.0: 1, 181.0: 1, 156.0: 1, 233.0: 1, 60.0: 1, 219.0: 1, 80.0: 1, 68.0: 1, 332.0: 1, 248.0: 1, 84.0: 1, 55.0: 1, 85.0: 1, 89.0: 1, 31.0: 1, 129.0: 1, 83.0: 1, 275.0: 1, 65.0: 1, 198.0: 1, 236.0: 1, 253.0: 1, 124.0: 1, 44.0: 1, 172.0: 1, 114.0: 1, 142.0: 1})\n",
      "Counter({109.0: 3, 139.0: 2, 88.0: 2, 180.0: 1, 144.0: 1, 163.0: 1, 147.0: 1, 97.0: 1, 220.0: 1, 190.0: 1, 191.0: 1, 122.0: 1, 230.0: 1, 242.0: 1, 248.0: 1, 249.0: 1, 192.0: 1, 131.0: 1, 237.0: 1, 78.0: 1, 135.0: 1, 244.0: 1, 199.0: 1, 270.0: 1, 164.0: 1, 72.0: 1, 96.0: 1, 306.0: 1, 91.0: 1, 214.0: 1, 95.0: 1, 216.0: 1, 263.0: 1, 178.0: 1, 113.0: 1, 200.0: 1, 148.0: 1, 243.0: 1, 71.0: 1, 77.0: 1})\n",
      "Counter({63.0: 2, 69.0: 2, 272.0: 1, 60.0: 1, 54.0: 1, 221.0: 1, 90.0: 1, 311.0: 1, 281.0: 1, 182.0: 1, 321.0: 1, 58.0: 1, 262.0: 1, 206.0: 1, 233.0: 1, 242.0: 1, 123.0: 1, 167.0: 1, 197.0: 1, 71.0: 1, 168.0: 1, 140.0: 1, 217.0: 1, 121.0: 1, 235.0: 1, 245.0: 1, 40.0: 1, 52.0: 1, 104.0: 1, 132.0: 1, 88.0: 1, 219.0: 1, 72.0: 1, 201.0: 1, 110.0: 1, 51.0: 1, 277.0: 1, 118.0: 1, 273.0: 1, 258.0: 1, 43.0: 1, 198.0: 1})\n",
      "Counter({72.0: 2, 242.0: 1, 232.0: 1, 175.0: 1, 93.0: 1, 168.0: 1, 275.0: 1, 293.0: 1, 281.0: 1, 140.0: 1, 189.0: 1, 181.0: 1, 209.0: 1, 136.0: 1, 261.0: 1, 113.0: 1, 131.0: 1, 174.0: 1, 257.0: 1, 55.0: 1, 84.0: 1, 42.0: 1, 146.0: 1, 212.0: 1, 233.0: 1, 91.0: 1, 111.0: 1, 152.0: 1, 120.0: 1, 67.0: 1, 310.0: 1, 94.0: 1, 183.0: 1, 66.0: 1, 173.0: 1, 49.0: 1, 64.0: 1, 48.0: 1, 178.0: 1, 104.0: 1, 132.0: 1, 220.0: 1, 57.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate( dt, X, y, scoring=scorer, cv=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 avg: -0.2044\n",
      "R2 std: 0.2989\n"
     ]
    }
   ],
   "source": [
    "r2_scores = scores['test_R2']\n",
    "r2_avg = round( np.mean(r2_scores), 4 )\n",
    "r2_std = round( np.std(r2_scores), 4 )\n",
    "print('R2 avg: {}'.format(r2_avg))\n",
    "print('R2 std: {}'.format(r2_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC avg: nan\n"
     ]
    }
   ],
   "source": [
    "auc_scores = scores['test_AUC']\n",
    "auc_avg = round( np.mean(auc_scores), 4 )\n",
    "print('AUC avg: {}'.format(auc_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({97.0: 2, 68.0: 2, 151.0: 1, 75.0: 1, 141.0: 1, 206.0: 1, 135.0: 1, 138.0: 1, 63.0: 1, 110.0: 1, 310.0: 1, 101.0: 1, 69.0: 1, 179.0: 1, 185.0: 1, 118.0: 1, 171.0: 1, 166.0: 1, 144.0: 1, 168.0: 1, 49.0: 1, 245.0: 1, 184.0: 1, 202.0: 1, 137.0: 1, 85.0: 1, 131.0: 1, 283.0: 1, 129.0: 1, 59.0: 1, 341.0: 1, 87.0: 1, 65.0: 1, 102.0: 1, 265.0: 1, 276.0: 1, 252.0: 1, 90.0: 1, 100.0: 1, 55.0: 1, 61.0: 1, 92.0: 1, 259.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({52.0: 3, 170.0: 3, 142.0: 2, 128.0: 2, 111.0: 2, 42.0: 2, 53.0: 1, 190.0: 1, 75.0: 1, 155.0: 1, 225.0: 1, 59.0: 1, 104.0: 1, 182.0: 1, 37.0: 1, 61.0: 1, 144.0: 1, 71.0: 1, 163.0: 1, 150.0: 1, 97.0: 1, 160.0: 1, 178.0: 1, 48.0: 1, 270.0: 1, 202.0: 1, 85.0: 1, 200.0: 1, 252.0: 1, 113.0: 1, 143.0: 1, 51.0: 1, 210.0: 1, 65.0: 1, 141.0: 1, 55.0: 1, 134.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({83.0: 2, 200.0: 2, 98.0: 1, 164.0: 1, 48.0: 1, 96.0: 1, 90.0: 1, 162.0: 1, 150.0: 1, 279.0: 1, 92.0: 1, 128.0: 1, 102.0: 1, 302.0: 1, 198.0: 1, 95.0: 1, 53.0: 1, 134.0: 1, 144.0: 1, 232.0: 1, 81.0: 1, 104.0: 1, 59.0: 1, 246.0: 1, 297.0: 1, 258.0: 1, 229.0: 1, 275.0: 1, 281.0: 1, 179.0: 1, 173.0: 1, 180.0: 1, 84.0: 1, 121.0: 1, 161.0: 1, 99.0: 1, 109.0: 1, 115.0: 1, 268.0: 1, 274.0: 1, 158.0: 1, 107.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({96.0: 2, 103.0: 1, 272.0: 1, 85.0: 1, 280.0: 1, 336.0: 1, 281.0: 1, 118.0: 1, 317.0: 1, 235.0: 1, 60.0: 1, 174.0: 1, 259.0: 1, 178.0: 1, 128.0: 1, 126.0: 1, 288.0: 1, 88.0: 1, 292.0: 1, 71.0: 1, 197.0: 1, 186.0: 1, 25.0: 1, 84.0: 1, 195.0: 1, 53.0: 1, 217.0: 1, 172.0: 1, 131.0: 1, 214.0: 1, 59.0: 1, 70.0: 1, 220.0: 1, 268.0: 1, 152.0: 1, 47.0: 1, 74.0: 1, 295.0: 1, 101.0: 1, 151.0: 1, 127.0: 1, 237.0: 1, 225.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({185.0: 2, 196.0: 2, 81.0: 1, 151.0: 1, 107.0: 1, 64.0: 1, 138.0: 1, 265.0: 1, 101.0: 1, 137.0: 1, 143.0: 1, 141.0: 1, 79.0: 1, 292.0: 1, 178.0: 1, 91.0: 1, 116.0: 1, 86.0: 1, 122.0: 1, 72.0: 1, 129.0: 1, 142.0: 1, 90.0: 1, 158.0: 1, 39.0: 1, 222.0: 1, 277.0: 1, 99.0: 1, 202.0: 1, 155.0: 1, 77.0: 1, 191.0: 1, 70.0: 1, 73.0: 1, 49.0: 1, 65.0: 1, 263.0: 1, 248.0: 1, 296.0: 1, 214.0: 1, 78.0: 1, 93.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({150.0: 2, 77.0: 2, 252.0: 1, 208.0: 1, 108.0: 1, 160.0: 1, 53.0: 1, 220.0: 1, 154.0: 1, 259.0: 1, 90.0: 1, 246.0: 1, 124.0: 1, 67.0: 1, 72.0: 1, 257.0: 1, 262.0: 1, 275.0: 1, 177.0: 1, 71.0: 1, 47.0: 1, 187.0: 1, 125.0: 1, 78.0: 1, 51.0: 1, 258.0: 1, 215.0: 1, 303.0: 1, 243.0: 1, 91.0: 1, 310.0: 1, 153.0: 1, 346.0: 1, 63.0: 1, 89.0: 1, 50.0: 1, 39.0: 1, 103.0: 1, 308.0: 1, 116.0: 1, 145.0: 1, 74.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94.0: 2, 200.0: 2, 45.0: 1, 115.0: 1, 264.0: 1, 87.0: 1, 202.0: 1, 127.0: 1, 182.0: 1, 241.0: 1, 66.0: 1, 283.0: 1, 64.0: 1, 102.0: 1, 265.0: 1, 230.0: 1, 181.0: 1, 156.0: 1, 233.0: 1, 60.0: 1, 219.0: 1, 80.0: 1, 68.0: 1, 332.0: 1, 248.0: 1, 84.0: 1, 55.0: 1, 85.0: 1, 89.0: 1, 31.0: 1, 129.0: 1, 83.0: 1, 275.0: 1, 65.0: 1, 198.0: 1, 236.0: 1, 253.0: 1, 124.0: 1, 44.0: 1, 172.0: 1, 114.0: 1, 142.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({109.0: 3, 139.0: 2, 88.0: 2, 180.0: 1, 144.0: 1, 163.0: 1, 147.0: 1, 97.0: 1, 220.0: 1, 190.0: 1, 191.0: 1, 122.0: 1, 230.0: 1, 242.0: 1, 248.0: 1, 249.0: 1, 192.0: 1, 131.0: 1, 237.0: 1, 78.0: 1, 135.0: 1, 244.0: 1, 199.0: 1, 270.0: 1, 164.0: 1, 72.0: 1, 96.0: 1, 306.0: 1, 91.0: 1, 214.0: 1, 95.0: 1, 216.0: 1, 263.0: 1, 178.0: 1, 113.0: 1, 200.0: 1, 148.0: 1, 243.0: 1, 71.0: 1, 77.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({63.0: 2, 69.0: 2, 272.0: 1, 60.0: 1, 54.0: 1, 221.0: 1, 90.0: 1, 311.0: 1, 281.0: 1, 182.0: 1, 321.0: 1, 58.0: 1, 262.0: 1, 206.0: 1, 233.0: 1, 242.0: 1, 123.0: 1, 167.0: 1, 197.0: 1, 71.0: 1, 168.0: 1, 140.0: 1, 217.0: 1, 121.0: 1, 235.0: 1, 245.0: 1, 40.0: 1, 52.0: 1, 104.0: 1, 132.0: 1, 88.0: 1, 219.0: 1, 72.0: 1, 201.0: 1, 110.0: 1, 51.0: 1, 277.0: 1, 118.0: 1, 273.0: 1, 258.0: 1, 43.0: 1, 198.0: 1})\n",
      "Counter({72.0: 2, 242.0: 1, 232.0: 1, 175.0: 1, 93.0: 1, 168.0: 1, 275.0: 1, 293.0: 1, 281.0: 1, 140.0: 1, 189.0: 1, 181.0: 1, 209.0: 1, 136.0: 1, 261.0: 1, 113.0: 1, 131.0: 1, 174.0: 1, 257.0: 1, 55.0: 1, 84.0: 1, 42.0: 1, 146.0: 1, 212.0: 1, 233.0: 1, 91.0: 1, 111.0: 1, 152.0: 1, 120.0: 1, 67.0: 1, 310.0: 1, 94.0: 1, 183.0: 1, 66.0: 1, 173.0: 1, 49.0: 1, 64.0: 1, 48.0: 1, 178.0: 1, 104.0: 1, 132.0: 1, 220.0: 1, 57.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:811: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate( rf, X, y, scoring=scorer, cv=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 avg: 0.3963\n",
      "R2 std: 0.1006\n"
     ]
    }
   ],
   "source": [
    "r2_scores = scores['test_R2']\n",
    "r2_avg = round( np.mean(r2_scores), 4 )\n",
    "r2_std = round( np.std(r2_scores), 4 )\n",
    "print('R2 avg: {}'.format(r2_avg))\n",
    "print('R2 std: {}'.format(r2_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = cross_validate( \n",
    "#    dt, X, y, \n",
    "#    scoring=make_scorer(roc_auc_score, average=\"weighted\", multi_class=\"ovr\"), \n",
    "#    cv=10 \n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "0.26666666666666666\n",
      "CategoricaliNB\n",
      "0.9\n",
      "ComplementNB\n",
      "0.5666666666666667\n",
      "GaussianNB\n",
      "0.9666666666666667\n",
      "MultinomialNB\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print('BernoulliNB')\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "print( bnb.score(X_test, y_test) )\n",
    "\n",
    "print('CategoricaliNB')\n",
    "catnb = CategoricalNB()\n",
    "catnb.fit(X_train, y_train)\n",
    "print( catnb.score(X_test, y_test) )\n",
    "\n",
    "print('ComplementNB')\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "print( cnb.score(X_test, y_test) )\n",
    "\n",
    "print('GaussianNB')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print( gnb.score(X_test, y_test) )\n",
    "\n",
    "print('MultinomialNB')\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "print( mnb.score(X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test = iris.data[:120], iris.data[120:]\n",
    "y_train, y_test = iris.target[:120], iris.target[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "lda.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "qda.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9800 pm 0.0427\n",
      "Recall: 0.9800 pm 0.0427\n",
      "Precision: 0.9811 pm 0.0416\n"
     ]
    }
   ],
   "source": [
    "scorer = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'Precision': make_scorer(precision_score, average='weighted')\n",
    "}\n",
    "scores = cross_validate( lda, X, y, scoring=scorer, cv=10)\n",
    "\n",
    "print('Accuracy: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Accuracy']), np.std(scores['test_Accuracy']) ))\n",
    "print('Recall: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Recall']), np.std(scores['test_Recall']) ))\n",
    "print('Precision: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Precision']), np.std(scores['test_Precision']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9800 pm 0.0427\n",
      "Recall: 0.9800 pm 0.0427\n",
      "Precision: 0.9811 pm 0.0416\n"
     ]
    }
   ],
   "source": [
    "scorer = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Recall': make_scorer(recall_score, average='weighted'),\n",
    "    'Precision': make_scorer(precision_score, average='weighted')\n",
    "}\n",
    "scores = cross_validate( qda, X, y, scoring=scorer, cv=10)\n",
    "\n",
    "print('Accuracy: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Accuracy']), np.std(scores['test_Accuracy']) ))\n",
    "print('Recall: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Recall']), np.std(scores['test_Recall']) ))\n",
    "print('Precision: {:.4f} pm {:.4f}'.format( np.mean(scores['test_Precision']), np.std(scores['test_Precision']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X_train, X_test = diabetes.data[:120], diabetes.data[120:]\n",
    "y_train, y_test = diabetes.target[:120], diabetes.target[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200., 173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274.,\n",
       "       158., 107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317.,\n",
       "       235.,  60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,\n",
       "        71., 197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131.,\n",
       "       214.,  59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151.,\n",
       "       127., 237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101.,\n",
       "       137., 143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72.,\n",
       "       129., 142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202.,\n",
       "       155.,  77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214.,\n",
       "       185.,  78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53.,\n",
       "       220., 154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275.,\n",
       "       177.,  71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,\n",
       "        91., 150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308.,\n",
       "       116., 145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,\n",
       "        66.,  94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156.,\n",
       "       233.,  60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,\n",
       "        89.,  31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44.,\n",
       "       172., 114., 142., 109., 180., 144., 163., 147.,  97., 220., 190.,\n",
       "       109., 191., 122., 230., 242., 248., 249., 192., 131., 237.,  78.,\n",
       "       135., 244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95.,\n",
       "       216., 263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,\n",
       "        71.,  77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182.,\n",
       "       321.,  58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71.,\n",
       "       168., 140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,\n",
       "        69., 219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273.,\n",
       "       258.,  43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,\n",
       "        72., 140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,\n",
       "        55.,  84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67.,\n",
       "       310.,  94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104.,\n",
       "       132., 220.,  57.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003105590062111801"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "lda.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has only 1 sample in class 37.0, covariance is ill defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ea6e62fa4eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mqda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 raise ValueError('y has only 1 sample in class %s, covariance '\n\u001b[0m\u001b[1;32m    709\u001b[0m                                  'is ill defined.' % str(self.classes_[ind]))\n\u001b[1;32m    710\u001b[0m             \u001b[0mXgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y has only 1 sample in class 37.0, covariance is ill defined."
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "qda.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test = iris.data[:120], iris.data[120:]\n",
    "y_train, y_test = iris.target[:120], iris.target[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X_train, X_test = diabetes.data[:120], diabetes.data[120:]\n",
    "y_train, y_test = diabetes.target[:120], diabetes.target[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003105590062111801"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
